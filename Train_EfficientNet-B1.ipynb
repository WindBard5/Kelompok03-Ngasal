{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dcb560e",
   "metadata": {},
   "source": [
    "# PRESENSI MAHASISWA DENGAN FACE RECOGNITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce8e7725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76d8fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# KONFIGURASI\n",
    "# ==========================\n",
    "\n",
    "DATASET_DIR = \"dataset/split\"   # berisi train/ dan val/\n",
    "TRAIN_DIR = os.path.join(DATASET_DIR, \"train\")\n",
    "VAL_DIR = os.path.join(DATASET_DIR, \"val\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "INPUT_SIZE = 224   # harus sama dengan ukuran crop wajah\n",
    "\n",
    "NUM_WORKERS = 0    # bisa dinaikkan kalau CPU kamu kuat\n",
    "FINE_TUNE_MODE = \"none\"  # opsi: \"none\", \"partial\", \"full\"\n",
    "SEED = 42\n",
    "MODEL_NAME = \"efficientnet_b1.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30c206f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# UTILITAS\n",
    "# ==========================\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def ensure_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b3e41cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# DATASET & DATALOADER\n",
    "# ==========================\n",
    "\n",
    "def get_dataloaders(input_size=224, batch_size=16, num_workers=2):\n",
    "    # Augmentasi untuk train\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],  # ImageNet mean\n",
    "            std=[0.229, 0.224, 0.225]    # ImageNet std\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    # Transform untuk val (tanpa augmentasi)\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transform)\n",
    "    val_dataset = datasets.ImageFolder(VAL_DIR, transform=val_transform)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    class_names = train_dataset.classes  # list nama folder kelas (NIM)\n",
    "    return train_loader, val_loader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e29e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# EfficientNet-B1 pre-trained\n",
    "# ==========================\n",
    "\n",
    "def build_model(num_classes):\n",
    "    try:\n",
    "        weights = models.EfficientNet_B1_Weights.IMAGENET1K_V1\n",
    "        model = models.efficientnet_b1(weights=weights)\n",
    "    except:\n",
    "        model = models.efficientnet_b1(pretrained=True)\n",
    "\n",
    "    # ------- 1) Set semua layer awalnya frozen dulu -------\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # ------- 2) Atur mode fine-tuning -------\n",
    "    mode = FINE_TUNE_MODE.lower()\n",
    "\n",
    "    if mode == \"none\":\n",
    "        # NO fine-tuning:\n",
    "        # semua layer EfficientNet tetap frozen,\n",
    "        # hanya classifier yang nanti akan dilatih.\n",
    "        print(\"[INFO] Fine-tuning mode: NONE (hanya classifier yang dilatih)\")\n",
    "\n",
    "    elif mode == \"partial\":\n",
    "        # PARTIAL fine-tuning:\n",
    "        # buka beberapa layer terakhir supaya bisa adaptasi ke domain wajah\n",
    "        print(\"[INFO] Fine-tuning mode: PARTIAL (unfreeze block terakhir)\")\n",
    "        for name, param in model.named_parameters():\n",
    "            # Block fitur terakhir EfficientNet-B1 biasanya di \"features.7\" & \"features.8\"\n",
    "            if \"features.7\" in name or \"features.8\" in name:\n",
    "                param.requires_grad = True\n",
    "\n",
    "    elif mode == \"full\":\n",
    "        # FULL fine-tuning:\n",
    "        # semua parameter boleh di-update\n",
    "        print(\"[INFO] Fine-tuning mode: FULL (semua layer dilatih)\")\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"FINE_TUNE_MODE tidak dikenal: {FINE_TUNE_MODE}. Gunakan 'none', 'partial', atau 'full'.\")\n",
    "\n",
    "    # ------- 3) Ganti classifier terakhir agar output = num_classes -------\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccc1a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    n_samples = 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = inputs.size(0)\n",
    "        running_loss += loss.item() * batch_size\n",
    "        running_corrects += torch.sum(preds == labels).item()\n",
    "        n_samples += batch_size\n",
    "\n",
    "    epoch_loss = running_loss / n_samples\n",
    "    epoch_acc = running_corrects / n_samples\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    n_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            batch_size = inputs.size(0)\n",
    "            running_loss += loss.item() * batch_size\n",
    "            running_corrects += torch.sum(preds == labels).item()\n",
    "            n_samples += batch_size\n",
    "\n",
    "    epoch_loss = running_loss / n_samples\n",
    "    epoch_acc = running_corrects / n_samples\n",
    "\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d3a3960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# VISUALISASI TRAINING\n",
    "# ==========================\n",
    "\n",
    "def plot_training_curves(history, output_dir=\"models\"):\n",
    "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
    "    plt.plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training & Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    loss_path = os.path.join(output_dir, \"loss_curve.png\")\n",
    "    plt.savefig(loss_path)\n",
    "    plt.close()\n",
    "    print(f\"Grafik loss disimpan ke: {loss_path}\")\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
    "    plt.plot(epochs, history[\"val_acc\"], label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training & Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    acc_path = os.path.join(output_dir, \"accuracy_curve.png\")\n",
    "    plt.savefig(acc_path)\n",
    "    plt.close()\n",
    "    print(f\"Grafik akurasi disimpan ke: {acc_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd77ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# EVALUASI LENGKAP (CM + F1)\n",
    "# ==========================\n",
    "\n",
    "def evaluate_full_metrics(model, dataloader, class_names, device, output_dir=\"models\"):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"\\n=== Confusion Matrix (angka) ===\")\n",
    "    print(cm)\n",
    "\n",
    "    # Visualisasi confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    cm_path = os.path.join(output_dir, \"confusion_matrix.png\")\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "    print(f\"Confusion matrix disimpan ke: {cm_path}\")\n",
    "\n",
    "    # Metrics lainnya (precision, recall, F1, support, accuracy)\n",
    "    print(\"\\n=== Classification Report (Precision, Recall, F1) ===\")\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "    print(report)\n",
    "\n",
    "    # Simpan juga ke file .txt\n",
    "    report_path = os.path.join(output_dir, \"classification_report.txt\")\n",
    "    with open(report_path, \"w\") as f:\n",
    "        f.write(report)\n",
    "    print(f\"Classification report disimpan ke: {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10503b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# VISUALISASI TRAINING\n",
    "# ==========================\n",
    "\n",
    "def plot_training_curves(history, output_dir=\"models\"):\n",
    "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
    "    plt.plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training & Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    loss_path = os.path.join(output_dir, \"loss_curve.png\")\n",
    "    plt.savefig(loss_path)\n",
    "    plt.close()\n",
    "    print(f\"Grafik loss disimpan ke: {loss_path}\")\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
    "    plt.plot(epochs, history[\"val_acc\"], label=\"Val Acc\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training & Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    acc_path = os.path.join(output_dir, \"accuracy_curve.png\")\n",
    "    plt.savefig(acc_path)\n",
    "    plt.close()\n",
    "    print(f\"Grafik akurasi disimpan ke: {acc_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a875cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah kelas (NIM): 70\n",
      "Daftar kelas: ['119140141', '120140156', '121140135', '122140001', '122140005', '122140006', '122140008', '122140009', '122140010', '122140012', '122140016', '122140018', '122140027', '122140038', '122140039', '122140043', '122140055', '122140056', '122140076', '122140077', '122140087', '122140095', '122140098', '122140100', '122140101', '122140103', '122140104', '122140107', '122140116', '122140117', '122140118', '122140119', '122140122', '122140127', '122140129', '122140130', '122140132', '122140134', '122140135', '122140137', '122140138', '122140140', '122140141', '122140144', '122140145', '122140150', '122140152', '122140153', '122140155', '122140156', '122140160', '122140163', '122140164', '122140165', '122140169', '122140170', '122140171', '122140172', '122140173', '122140182', '122140187', '122140198', '122140202', '122140207', '122140208', '122140209', '122140219', '122140222', '122140236', '122140239']\n",
      "[INFO] Fine-tuning mode: NONE (hanya classifier yang dilatih)\n",
      "\n",
      "Epoch 1/50\n",
      "----------------------------------------\n",
      "Train Loss: 4.3142  |  Train Acc: 0.0050\n",
      "Val   Loss: 4.2544  |  Val   Acc: 0.0423\n",
      "==> Model terbaik diperbarui (val_acc = 0.0423)\n",
      "\n",
      "Epoch 2/50\n",
      "----------------------------------------\n",
      "Train Loss: 4.2271  |  Train Acc: 0.0249\n",
      "Val   Loss: 4.1760  |  Val   Acc: 0.0423\n",
      "\n",
      "Epoch 3/50\n",
      "----------------------------------------\n",
      "Train Loss: 4.1549  |  Train Acc: 0.0348\n",
      "Val   Loss: 4.1323  |  Val   Acc: 0.0563\n",
      "==> Model terbaik diperbarui (val_acc = 0.0563)\n",
      "\n",
      "Epoch 4/50\n",
      "----------------------------------------\n",
      "Train Loss: 4.0685  |  Train Acc: 0.1194\n",
      "Val   Loss: 4.0910  |  Val   Acc: 0.0845\n",
      "==> Model terbaik diperbarui (val_acc = 0.0845)\n",
      "\n",
      "Epoch 5/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.9794  |  Train Acc: 0.1194\n",
      "Val   Loss: 4.0523  |  Val   Acc: 0.1127\n",
      "==> Model terbaik diperbarui (val_acc = 0.1127)\n",
      "\n",
      "Epoch 6/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.9029  |  Train Acc: 0.2289\n",
      "Val   Loss: 4.0179  |  Val   Acc: 0.1690\n",
      "==> Model terbaik diperbarui (val_acc = 0.1690)\n",
      "\n",
      "Epoch 7/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.8524  |  Train Acc: 0.2488\n",
      "Val   Loss: 3.9791  |  Val   Acc: 0.2535\n",
      "==> Model terbaik diperbarui (val_acc = 0.2535)\n",
      "\n",
      "Epoch 8/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.8092  |  Train Acc: 0.2488\n",
      "Val   Loss: 3.9399  |  Val   Acc: 0.3239\n",
      "==> Model terbaik diperbarui (val_acc = 0.3239)\n",
      "\n",
      "Epoch 9/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.7341  |  Train Acc: 0.3930\n",
      "Val   Loss: 3.8990  |  Val   Acc: 0.3380\n",
      "==> Model terbaik diperbarui (val_acc = 0.3380)\n",
      "\n",
      "Epoch 10/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.6870  |  Train Acc: 0.4478\n",
      "Val   Loss: 3.8667  |  Val   Acc: 0.3521\n",
      "==> Model terbaik diperbarui (val_acc = 0.3521)\n",
      "\n",
      "Epoch 11/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.6221  |  Train Acc: 0.5075\n",
      "Val   Loss: 3.8711  |  Val   Acc: 0.3521\n",
      "\n",
      "Epoch 12/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.6161  |  Train Acc: 0.4577\n",
      "Val   Loss: 3.8588  |  Val   Acc: 0.3662\n",
      "==> Model terbaik diperbarui (val_acc = 0.3662)\n",
      "\n",
      "Epoch 13/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.6389  |  Train Acc: 0.4826\n",
      "Val   Loss: 3.8581  |  Val   Acc: 0.3662\n",
      "\n",
      "Epoch 14/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.6079  |  Train Acc: 0.5224\n",
      "Val   Loss: 3.8601  |  Val   Acc: 0.3662\n",
      "\n",
      "Epoch 15/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5759  |  Train Acc: 0.5721\n",
      "Val   Loss: 3.8531  |  Val   Acc: 0.3662\n",
      "\n",
      "Epoch 16/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5961  |  Train Acc: 0.5124\n",
      "Val   Loss: 3.8479  |  Val   Acc: 0.3803\n",
      "==> Model terbaik diperbarui (val_acc = 0.3803)\n",
      "\n",
      "Epoch 17/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5673  |  Train Acc: 0.5721\n",
      "Val   Loss: 3.8486  |  Val   Acc: 0.3662\n",
      "\n",
      "Epoch 18/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5968  |  Train Acc: 0.5224\n",
      "Val   Loss: 3.8387  |  Val   Acc: 0.3803\n",
      "\n",
      "Epoch 19/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5719  |  Train Acc: 0.5572\n",
      "Val   Loss: 3.8340  |  Val   Acc: 0.3944\n",
      "==> Model terbaik diperbarui (val_acc = 0.3944)\n",
      "\n",
      "Epoch 20/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5872  |  Train Acc: 0.5821\n",
      "Val   Loss: 3.8241  |  Val   Acc: 0.3944\n",
      "\n",
      "Epoch 21/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5876  |  Train Acc: 0.5323\n",
      "Val   Loss: 3.8355  |  Val   Acc: 0.3662\n",
      "\n",
      "Epoch 22/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5600  |  Train Acc: 0.5871\n",
      "Val   Loss: 3.8352  |  Val   Acc: 0.3803\n",
      "\n",
      "Epoch 23/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5904  |  Train Acc: 0.5075\n",
      "Val   Loss: 3.8355  |  Val   Acc: 0.3521\n",
      "\n",
      "Epoch 24/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5396  |  Train Acc: 0.5323\n",
      "Val   Loss: 3.8347  |  Val   Acc: 0.3662\n",
      "\n",
      "Epoch 25/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5620  |  Train Acc: 0.5970\n",
      "Val   Loss: 3.8244  |  Val   Acc: 0.3803\n",
      "\n",
      "Epoch 26/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5844  |  Train Acc: 0.5672\n",
      "Val   Loss: 3.8303  |  Val   Acc: 0.3662\n",
      "\n",
      "Epoch 27/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5559  |  Train Acc: 0.5771\n",
      "Val   Loss: 3.8323  |  Val   Acc: 0.3662\n",
      "\n",
      "Epoch 28/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5575  |  Train Acc: 0.5771\n",
      "Val   Loss: 3.8305  |  Val   Acc: 0.3803\n",
      "\n",
      "Epoch 29/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5480  |  Train Acc: 0.5920\n",
      "Val   Loss: 3.8324  |  Val   Acc: 0.3803\n",
      "\n",
      "Epoch 30/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5582  |  Train Acc: 0.5672\n",
      "Val   Loss: 3.8355  |  Val   Acc: 0.3662\n",
      "\n",
      "Epoch 31/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5646  |  Train Acc: 0.5672\n",
      "Val   Loss: 3.8283  |  Val   Acc: 0.3803\n",
      "\n",
      "Epoch 32/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5569  |  Train Acc: 0.5721\n",
      "Val   Loss: 3.8250  |  Val   Acc: 0.3803\n",
      "\n",
      "Epoch 33/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5550  |  Train Acc: 0.5423\n",
      "Val   Loss: 3.8273  |  Val   Acc: 0.3944\n",
      "\n",
      "Epoch 34/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5911  |  Train Acc: 0.5423\n",
      "Val   Loss: 3.8302  |  Val   Acc: 0.3944\n",
      "\n",
      "Epoch 35/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5557  |  Train Acc: 0.5622\n",
      "Val   Loss: 3.8314  |  Val   Acc: 0.3944\n",
      "\n",
      "Epoch 36/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5819  |  Train Acc: 0.5323\n",
      "Val   Loss: 3.8361  |  Val   Acc: 0.3944\n",
      "\n",
      "Epoch 37/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5789  |  Train Acc: 0.5224\n",
      "Val   Loss: 3.8322  |  Val   Acc: 0.3662\n",
      "\n",
      "Epoch 38/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5670  |  Train Acc: 0.5771\n",
      "Val   Loss: 3.8322  |  Val   Acc: 0.3662\n",
      "\n",
      "Epoch 39/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5475  |  Train Acc: 0.6070\n",
      "Val   Loss: 3.8313  |  Val   Acc: 0.3662\n",
      "\n",
      "Epoch 40/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5547  |  Train Acc: 0.5572\n",
      "Val   Loss: 3.8246  |  Val   Acc: 0.3803\n",
      "\n",
      "Epoch 41/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5559  |  Train Acc: 0.5721\n",
      "Val   Loss: 3.8242  |  Val   Acc: 0.3803\n",
      "\n",
      "Epoch 42/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5470  |  Train Acc: 0.5721\n",
      "Val   Loss: 3.8297  |  Val   Acc: 0.3944\n",
      "\n",
      "Epoch 43/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5560  |  Train Acc: 0.5771\n",
      "Val   Loss: 3.8320  |  Val   Acc: 0.3521\n",
      "\n",
      "Epoch 44/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5341  |  Train Acc: 0.5622\n",
      "Val   Loss: 3.8279  |  Val   Acc: 0.3803\n",
      "\n",
      "Epoch 45/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5518  |  Train Acc: 0.5622\n",
      "Val   Loss: 3.8210  |  Val   Acc: 0.3944\n",
      "\n",
      "Epoch 46/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5711  |  Train Acc: 0.5423\n",
      "Val   Loss: 3.8255  |  Val   Acc: 0.3662\n",
      "\n",
      "Epoch 47/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5493  |  Train Acc: 0.5970\n",
      "Val   Loss: 3.8262  |  Val   Acc: 0.3662\n",
      "\n",
      "Epoch 48/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5257  |  Train Acc: 0.5572\n",
      "Val   Loss: 3.8273  |  Val   Acc: 0.3803\n",
      "\n",
      "Epoch 49/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5430  |  Train Acc: 0.6219\n",
      "Val   Loss: 3.8287  |  Val   Acc: 0.3662\n",
      "\n",
      "Epoch 50/50\n",
      "----------------------------------------\n",
      "Train Loss: 3.5633  |  Train Acc: 0.5721\n",
      "Val   Loss: 3.8275  |  Val   Acc: 0.3944\n",
      "\n",
      "===============================\n",
      "Training selesai\n",
      "Waktu total: 10.58 menit\n",
      "Akurasi validasi terbaik: 0.3944\n",
      "===============================\n",
      "\n",
      "Membuat grafik training (loss & accuracy)...\n",
      "Grafik loss disimpan ke: models\\loss_curve.png\n",
      "Grafik akurasi disimpan ke: models\\accuracy_curve.png\n",
      "\n",
      "Melakukan evaluasi lengkap pada data validasi...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Confusion Matrix (angka) ===\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Confusion matrix disimpan ke: models\\confusion_matrix.png\n",
      "\n",
      "=== Classification Report (Precision, Recall, F1) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   119140141       0.00      0.00      0.00         1\n",
      "   120140156       1.00      1.00      1.00         1\n",
      "   121140135       0.00      0.00      0.00         1\n",
      "   122140001       0.00      0.00      0.00         1\n",
      "   122140005       0.00      0.00      0.00         1\n",
      "   122140006       0.00      0.00      0.00         1\n",
      "   122140008       0.00      0.00      0.00         1\n",
      "   122140009       0.00      0.00      0.00         1\n",
      "   122140010       0.00      0.00      0.00         1\n",
      "   122140012       1.00      1.00      1.00         1\n",
      "   122140016       0.00      0.00      0.00         1\n",
      "   122140018       1.00      1.00      1.00         1\n",
      "   122140027       0.00      0.00      0.00         1\n",
      "   122140038       1.00      1.00      1.00         1\n",
      "   122140039       0.50      1.00      0.67         1\n",
      "   122140043       0.50      1.00      0.67         1\n",
      "   122140055       0.00      0.00      0.00         1\n",
      "   122140056       0.00      0.00      0.00         1\n",
      "   122140076       0.00      0.00      0.00         1\n",
      "   122140077       0.00      0.00      0.00         1\n",
      "   122140087       0.33      1.00      0.50         1\n",
      "   122140095       0.50      1.00      0.67         1\n",
      "   122140098       0.00      0.00      0.00         1\n",
      "   122140100       0.00      0.00      0.00         1\n",
      "   122140101       0.00      0.00      0.00         1\n",
      "   122140103       0.00      0.00      0.00         1\n",
      "   122140104       0.50      1.00      0.67         1\n",
      "   122140107       0.00      0.00      0.00         1\n",
      "   122140116       0.50      1.00      0.67         1\n",
      "   122140117       1.00      1.00      1.00         1\n",
      "   122140118       0.00      0.00      0.00         1\n",
      "   122140119       0.00      0.00      0.00         1\n",
      "   122140122       0.00      0.00      0.00         1\n",
      "   122140127       1.00      1.00      1.00         1\n",
      "   122140129       0.00      0.00      0.00         1\n",
      "   122140130       0.00      0.00      0.00         1\n",
      "   122140132       0.00      0.00      0.00         1\n",
      "   122140134       0.00      0.00      0.00         1\n",
      "   122140135       0.00      0.00      0.00         1\n",
      "   122140137       1.00      1.00      1.00         1\n",
      "   122140138       0.33      1.00      0.50         1\n",
      "   122140140       0.33      1.00      0.50         1\n",
      "   122140141       0.67      1.00      0.80         2\n",
      "   122140144       1.00      1.00      1.00         1\n",
      "   122140145       0.50      1.00      0.67         1\n",
      "   122140150       0.50      1.00      0.67         1\n",
      "   122140152       0.00      0.00      0.00         1\n",
      "   122140153       0.00      0.00      0.00         1\n",
      "   122140155       0.00      0.00      0.00         1\n",
      "   122140156       0.00      0.00      0.00         1\n",
      "   122140160       0.25      1.00      0.40         1\n",
      "   122140163       0.00      0.00      0.00         1\n",
      "   122140164       1.00      1.00      1.00         1\n",
      "   122140165       1.00      1.00      1.00         1\n",
      "   122140169       0.25      1.00      0.40         1\n",
      "   122140170       0.00      0.00      0.00         1\n",
      "   122140171       0.20      1.00      0.33         1\n",
      "   122140172       0.00      0.00      0.00         1\n",
      "   122140173       0.00      0.00      0.00         1\n",
      "   122140182       0.50      1.00      0.67         1\n",
      "   122140187       0.25      1.00      0.40         1\n",
      "   122140198       0.00      0.00      0.00         1\n",
      "   122140202       0.00      0.00      0.00         1\n",
      "   122140207       0.00      0.00      0.00         1\n",
      "   122140208       0.00      0.00      0.00         1\n",
      "   122140209       0.00      0.00      0.00         1\n",
      "   122140219       0.00      0.00      0.00         1\n",
      "   122140222       0.00      0.00      0.00         1\n",
      "   122140236       1.00      1.00      1.00         1\n",
      "   122140239       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.39        71\n",
      "   macro avg       0.25      0.39      0.29        71\n",
      "weighted avg       0.26      0.39      0.30        71\n",
      "\n",
      "Classification report disimpan ke: models\\classification_report.txt\n",
      "\n",
      "Model terbaik disimpan ke: models\\efficientnet_b1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_true = type_of_target(y_true, input_name=\"y_true\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n",
      "  ys_types = set(type_of_target(x) for x in ys)\n",
      "c:\\Users\\SIDDIQ\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# MAIN TRAINING LOOP\n",
    "# ==========================\n",
    "\n",
    "def main():\n",
    "    set_seed(SEED)\n",
    "\n",
    "    device = \"cpu\"\n",
    "\n",
    "    # Pastikan folder dataset ada\n",
    "    if not os.path.isdir(TRAIN_DIR) or not os.path.isdir(VAL_DIR):\n",
    "        print(f\"Folder train/val tidak ditemukan di: {DATASET_DIR}\")\n",
    "        return\n",
    "\n",
    "    train_loader, val_loader, class_names = get_dataloaders(\n",
    "        input_size=INPUT_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    num_classes = len(class_names)\n",
    "    print(f\"Jumlah kelas (NIM): {num_classes}\")\n",
    "    print(\"Daftar kelas:\", class_names)\n",
    "\n",
    "    model = build_model(num_classes=num_classes)\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "\n",
    "    # Scheduler: turunkan LR setiap beberapa epoch\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=10,\n",
    "        gamma=0.1\n",
    "    )\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": []\n",
    "    }\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, device\n",
    "        )\n",
    "        val_loss, val_acc = evaluate(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f}  |  Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f}  |  Val   Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Simpan model terbaik berdasarkan val_acc\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            print(f\"==> Model terbaik diperbarui (val_acc = {best_val_acc:.4f})\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(\"\\n===============================\")\n",
    "    print(\"Training selesai\")\n",
    "    print(f\"Waktu total: {total_time/60:.2f} menit\")\n",
    "    print(f\"Akurasi validasi terbaik: {best_val_acc:.4f}\")\n",
    "    print(\"===============================\")\n",
    "\n",
    "    # Load weight terbaik\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    # Pastikan folder models ada\n",
    "    ensure_dir(\"models\")\n",
    "\n",
    "    # Visualisasi kurva training\n",
    "    print(\"\\nMembuat grafik training (loss & accuracy)...\")\n",
    "    plot_training_curves(history, output_dir=\"models\")\n",
    "\n",
    "    # Evaluasi lengkap di data validasi (confusion matrix + F1, precision, recall)\n",
    "    print(\"\\nMelakukan evaluasi lengkap pada data validasi...\")\n",
    "    evaluate_full_metrics(model, val_loader, class_names, device, output_dir=\"models\")\n",
    "\n",
    "    # Simpan model\n",
    "    model_path = os.path.join(\"models\", MODEL_NAME)\n",
    "    torch.save({\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"class_names\": class_names\n",
    "    }, model_path)\n",
    "    print(f\"\\nModel terbaik disimpan ke: {model_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
